{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```text\n",
    "Non Linear Network\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "images.shape: torch.Size([128, 3, 32, 32])\n",
      "labels.shape: torch.Size([128])\n",
      "Epoch 1/250, Loss: 1.8700, Accuracy: 33.28%\n",
      "Epoch 2/250, Loss: 1.7406, Accuracy: 38.14%\n",
      "Epoch 3/250, Loss: 1.6804, Accuracy: 39.97%\n",
      "Epoch 4/250, Loss: 1.6440, Accuracy: 41.63%\n",
      "Epoch 5/250, Loss: 1.6170, Accuracy: 42.68%\n",
      "Epoch 6/250, Loss: 1.5952, Accuracy: 43.85%\n",
      "Epoch 7/250, Loss: 1.5772, Accuracy: 44.33%\n",
      "Epoch 8/250, Loss: 1.5619, Accuracy: 44.86%\n",
      "Epoch 9/250, Loss: 1.5491, Accuracy: 45.30%\n",
      "Epoch 10/250, Loss: 1.5383, Accuracy: 45.54%\n",
      "Epoch 11/250, Loss: 1.5288, Accuracy: 46.06%\n",
      "Epoch 12/250, Loss: 1.5197, Accuracy: 46.42%\n",
      "Epoch 13/250, Loss: 1.5122, Accuracy: 46.73%\n",
      "Epoch 14/250, Loss: 1.5055, Accuracy: 46.97%\n",
      "Epoch 15/250, Loss: 1.4994, Accuracy: 47.22%\n",
      "Epoch 16/250, Loss: 1.4944, Accuracy: 47.30%\n",
      "Epoch 17/250, Loss: 1.4892, Accuracy: 47.47%\n",
      "Epoch 18/250, Loss: 1.4850, Accuracy: 47.72%\n",
      "Epoch 19/250, Loss: 1.4809, Accuracy: 47.84%\n",
      "Epoch 20/250, Loss: 1.4770, Accuracy: 47.93%\n",
      "Epoch 21/250, Loss: 1.4734, Accuracy: 48.01%\n",
      "Epoch 22/250, Loss: 1.4704, Accuracy: 48.07%\n",
      "Epoch 23/250, Loss: 1.4676, Accuracy: 48.29%\n",
      "Epoch 24/250, Loss: 1.4653, Accuracy: 48.45%\n",
      "Epoch 25/250, Loss: 1.4628, Accuracy: 48.56%\n",
      "Epoch 26/250, Loss: 1.4602, Accuracy: 48.67%\n",
      "Epoch 27/250, Loss: 1.4581, Accuracy: 48.76%\n",
      "Epoch 28/250, Loss: 1.4561, Accuracy: 48.82%\n",
      "Epoch 29/250, Loss: 1.4543, Accuracy: 48.74%\n",
      "Epoch 30/250, Loss: 1.4526, Accuracy: 48.80%\n",
      "Epoch 31/250, Loss: 1.4509, Accuracy: 48.76%\n",
      "Epoch 32/250, Loss: 1.4493, Accuracy: 48.77%\n",
      "Epoch 33/250, Loss: 1.4477, Accuracy: 48.80%\n",
      "Epoch 34/250, Loss: 1.4465, Accuracy: 48.86%\n",
      "Epoch 35/250, Loss: 1.4450, Accuracy: 48.86%\n",
      "Epoch 36/250, Loss: 1.4436, Accuracy: 48.91%\n",
      "Epoch 37/250, Loss: 1.4428, Accuracy: 48.95%\n",
      "Epoch 38/250, Loss: 1.4418, Accuracy: 48.97%\n",
      "Epoch 39/250, Loss: 1.4409, Accuracy: 49.16%\n",
      "Epoch 40/250, Loss: 1.4402, Accuracy: 49.31%\n",
      "Epoch 41/250, Loss: 1.4396, Accuracy: 49.36%\n",
      "Epoch 42/250, Loss: 1.4392, Accuracy: 49.30%\n",
      "Epoch 43/250, Loss: 1.4390, Accuracy: 49.35%\n",
      "Epoch 44/250, Loss: 1.4384, Accuracy: 49.44%\n",
      "Epoch 45/250, Loss: 1.4380, Accuracy: 49.51%\n",
      "Epoch 46/250, Loss: 1.4371, Accuracy: 49.52%\n",
      "Epoch 47/250, Loss: 1.4369, Accuracy: 49.54%\n",
      "Epoch 48/250, Loss: 1.4367, Accuracy: 49.60%\n",
      "Epoch 49/250, Loss: 1.4367, Accuracy: 49.57%\n",
      "Epoch 50/250, Loss: 1.4370, Accuracy: 49.57%\n",
      "Epoch 51/250, Loss: 1.4371, Accuracy: 49.60%\n",
      "Epoch 52/250, Loss: 1.4371, Accuracy: 49.49%\n",
      "Epoch 53/250, Loss: 1.4371, Accuracy: 49.62%\n",
      "Epoch 54/250, Loss: 1.4377, Accuracy: 49.60%\n",
      "Epoch 55/250, Loss: 1.4379, Accuracy: 49.62%\n",
      "Epoch 56/250, Loss: 1.4383, Accuracy: 49.64%\n",
      "Epoch 57/250, Loss: 1.4390, Accuracy: 49.69%\n",
      "Epoch 58/250, Loss: 1.4394, Accuracy: 49.66%\n",
      "Epoch 59/250, Loss: 1.4396, Accuracy: 49.79%\n",
      "Epoch 60/250, Loss: 1.4403, Accuracy: 49.75%\n",
      "Epoch 61/250, Loss: 1.4407, Accuracy: 49.90%\n",
      "Epoch 62/250, Loss: 1.4416, Accuracy: 49.86%\n",
      "Epoch 63/250, Loss: 1.4424, Accuracy: 49.91%\n",
      "Epoch 64/250, Loss: 1.4429, Accuracy: 50.02%\n",
      "Epoch 65/250, Loss: 1.4436, Accuracy: 50.05%\n",
      "Epoch 66/250, Loss: 1.4445, Accuracy: 50.08%\n",
      "Epoch 67/250, Loss: 1.4452, Accuracy: 50.09%\n",
      "Epoch 68/250, Loss: 1.4460, Accuracy: 50.15%\n",
      "Epoch 69/250, Loss: 1.4467, Accuracy: 50.09%\n",
      "Epoch 70/250, Loss: 1.4478, Accuracy: 50.10%\n",
      "Epoch 71/250, Loss: 1.4487, Accuracy: 50.05%\n",
      "Epoch 72/250, Loss: 1.4498, Accuracy: 50.06%\n",
      "Epoch 73/250, Loss: 1.4505, Accuracy: 50.04%\n",
      "Epoch 74/250, Loss: 1.4517, Accuracy: 49.98%\n",
      "Epoch 75/250, Loss: 1.4527, Accuracy: 49.92%\n",
      "Epoch 76/250, Loss: 1.4540, Accuracy: 49.98%\n",
      "Epoch 77/250, Loss: 1.4552, Accuracy: 49.94%\n",
      "Epoch 78/250, Loss: 1.4561, Accuracy: 50.02%\n",
      "Epoch 79/250, Loss: 1.4574, Accuracy: 49.96%\n",
      "Epoch 80/250, Loss: 1.4586, Accuracy: 49.95%\n",
      "Epoch 81/250, Loss: 1.4596, Accuracy: 49.86%\n",
      "Epoch 82/250, Loss: 1.4608, Accuracy: 49.79%\n",
      "Epoch 83/250, Loss: 1.4621, Accuracy: 49.73%\n",
      "Epoch 84/250, Loss: 1.4635, Accuracy: 49.74%\n",
      "Epoch 85/250, Loss: 1.4648, Accuracy: 49.72%\n",
      "Epoch 86/250, Loss: 1.4661, Accuracy: 49.67%\n",
      "Epoch 87/250, Loss: 1.4670, Accuracy: 49.77%\n",
      "Epoch 88/250, Loss: 1.4684, Accuracy: 49.68%\n",
      "Epoch 89/250, Loss: 1.4699, Accuracy: 49.70%\n",
      "Epoch 90/250, Loss: 1.4709, Accuracy: 49.71%\n",
      "Epoch 91/250, Loss: 1.4727, Accuracy: 49.74%\n",
      "Epoch 92/250, Loss: 1.4743, Accuracy: 49.73%\n",
      "Epoch 93/250, Loss: 1.4758, Accuracy: 49.68%\n",
      "Epoch 94/250, Loss: 1.4770, Accuracy: 49.67%\n",
      "Epoch 95/250, Loss: 1.4784, Accuracy: 49.64%\n",
      "Epoch 96/250, Loss: 1.4797, Accuracy: 49.63%\n",
      "Epoch 97/250, Loss: 1.4812, Accuracy: 49.49%\n",
      "Epoch 98/250, Loss: 1.4826, Accuracy: 49.47%\n",
      "Epoch 99/250, Loss: 1.4842, Accuracy: 49.39%\n",
      "Epoch 100/250, Loss: 1.4857, Accuracy: 49.44%\n",
      "Epoch 101/250, Loss: 1.4869, Accuracy: 49.39%\n",
      "Epoch 102/250, Loss: 1.4888, Accuracy: 49.40%\n",
      "Epoch 103/250, Loss: 1.4907, Accuracy: 49.39%\n",
      "Epoch 104/250, Loss: 1.4916, Accuracy: 49.44%\n",
      "Epoch 105/250, Loss: 1.4935, Accuracy: 49.30%\n",
      "Epoch 106/250, Loss: 1.4956, Accuracy: 49.35%\n",
      "Epoch 107/250, Loss: 1.4976, Accuracy: 49.27%\n",
      "Epoch 108/250, Loss: 1.4988, Accuracy: 49.23%\n",
      "Epoch 109/250, Loss: 1.5004, Accuracy: 49.16%\n",
      "Epoch 110/250, Loss: 1.5021, Accuracy: 49.16%\n",
      "Epoch 111/250, Loss: 1.5036, Accuracy: 49.07%\n",
      "Epoch 112/250, Loss: 1.5057, Accuracy: 49.06%\n",
      "Epoch 113/250, Loss: 1.5073, Accuracy: 49.07%\n",
      "Epoch 114/250, Loss: 1.5090, Accuracy: 49.03%\n",
      "Epoch 115/250, Loss: 1.5110, Accuracy: 48.96%\n",
      "Epoch 116/250, Loss: 1.5125, Accuracy: 48.95%\n",
      "Epoch 117/250, Loss: 1.5145, Accuracy: 48.78%\n",
      "Epoch 118/250, Loss: 1.5167, Accuracy: 48.80%\n",
      "Epoch 119/250, Loss: 1.5184, Accuracy: 48.71%\n",
      "Epoch 120/250, Loss: 1.5201, Accuracy: 48.68%\n",
      "Epoch 121/250, Loss: 1.5217, Accuracy: 48.76%\n",
      "Epoch 122/250, Loss: 1.5239, Accuracy: 48.62%\n",
      "Epoch 123/250, Loss: 1.5254, Accuracy: 48.65%\n",
      "Epoch 124/250, Loss: 1.5270, Accuracy: 48.61%\n",
      "Epoch 125/250, Loss: 1.5291, Accuracy: 48.61%\n",
      "Epoch 126/250, Loss: 1.5314, Accuracy: 48.54%\n",
      "Epoch 127/250, Loss: 1.5327, Accuracy: 48.53%\n",
      "Epoch 128/250, Loss: 1.5349, Accuracy: 48.51%\n",
      "Epoch 129/250, Loss: 1.5365, Accuracy: 48.36%\n",
      "Epoch 130/250, Loss: 1.5386, Accuracy: 48.37%\n",
      "Epoch 131/250, Loss: 1.5399, Accuracy: 48.42%\n",
      "Epoch 132/250, Loss: 1.5419, Accuracy: 48.25%\n",
      "Epoch 133/250, Loss: 1.5436, Accuracy: 48.30%\n",
      "Epoch 134/250, Loss: 1.5457, Accuracy: 48.21%\n",
      "Epoch 135/250, Loss: 1.5474, Accuracy: 48.16%\n",
      "Epoch 136/250, Loss: 1.5488, Accuracy: 48.13%\n",
      "Epoch 137/250, Loss: 1.5504, Accuracy: 48.21%\n",
      "Epoch 138/250, Loss: 1.5524, Accuracy: 48.14%\n",
      "Epoch 139/250, Loss: 1.5544, Accuracy: 48.19%\n",
      "Epoch 140/250, Loss: 1.5562, Accuracy: 48.11%\n",
      "Epoch 141/250, Loss: 1.5580, Accuracy: 48.15%\n",
      "Epoch 142/250, Loss: 1.5605, Accuracy: 48.10%\n",
      "Epoch 143/250, Loss: 1.5625, Accuracy: 48.15%\n",
      "Epoch 144/250, Loss: 1.5639, Accuracy: 48.11%\n",
      "Epoch 145/250, Loss: 1.5668, Accuracy: 48.07%\n",
      "Epoch 146/250, Loss: 1.5686, Accuracy: 48.07%\n",
      "Epoch 147/250, Loss: 1.5706, Accuracy: 48.08%\n",
      "Epoch 148/250, Loss: 1.5729, Accuracy: 47.96%\n",
      "Epoch 149/250, Loss: 1.5742, Accuracy: 48.00%\n",
      "Epoch 150/250, Loss: 1.5766, Accuracy: 47.99%\n",
      "Epoch 151/250, Loss: 1.5782, Accuracy: 48.02%\n",
      "Epoch 152/250, Loss: 1.5801, Accuracy: 47.95%\n",
      "Epoch 153/250, Loss: 1.5822, Accuracy: 47.98%\n",
      "Epoch 154/250, Loss: 1.5843, Accuracy: 48.01%\n",
      "Epoch 155/250, Loss: 1.5858, Accuracy: 48.05%\n",
      "Epoch 156/250, Loss: 1.5882, Accuracy: 48.09%\n",
      "Epoch 157/250, Loss: 1.5905, Accuracy: 48.03%\n",
      "Epoch 158/250, Loss: 1.5921, Accuracy: 47.99%\n",
      "Epoch 159/250, Loss: 1.5941, Accuracy: 47.98%\n",
      "Epoch 160/250, Loss: 1.5958, Accuracy: 47.95%\n",
      "Epoch 161/250, Loss: 1.5978, Accuracy: 47.97%\n",
      "Epoch 162/250, Loss: 1.5999, Accuracy: 47.88%\n",
      "Epoch 163/250, Loss: 1.6012, Accuracy: 47.87%\n",
      "Epoch 164/250, Loss: 1.6029, Accuracy: 47.85%\n",
      "Epoch 165/250, Loss: 1.6057, Accuracy: 47.81%\n",
      "Epoch 166/250, Loss: 1.6068, Accuracy: 47.81%\n",
      "Epoch 167/250, Loss: 1.6089, Accuracy: 47.81%\n",
      "Epoch 168/250, Loss: 1.6108, Accuracy: 47.79%\n",
      "Epoch 169/250, Loss: 1.6128, Accuracy: 47.81%\n",
      "Epoch 170/250, Loss: 1.6144, Accuracy: 47.72%\n",
      "Epoch 171/250, Loss: 1.6164, Accuracy: 47.78%\n",
      "Epoch 172/250, Loss: 1.6175, Accuracy: 47.62%\n",
      "Epoch 173/250, Loss: 1.6195, Accuracy: 47.63%\n",
      "Epoch 174/250, Loss: 1.6216, Accuracy: 47.59%\n",
      "Epoch 175/250, Loss: 1.6225, Accuracy: 47.73%\n",
      "Epoch 176/250, Loss: 1.6251, Accuracy: 47.57%\n",
      "Epoch 177/250, Loss: 1.6281, Accuracy: 47.48%\n",
      "Epoch 178/250, Loss: 1.6292, Accuracy: 47.52%\n",
      "Epoch 179/250, Loss: 1.6315, Accuracy: 47.49%\n",
      "Epoch 180/250, Loss: 1.6336, Accuracy: 47.39%\n",
      "Epoch 181/250, Loss: 1.6354, Accuracy: 47.52%\n",
      "Epoch 182/250, Loss: 1.6373, Accuracy: 47.38%\n",
      "Epoch 183/250, Loss: 1.6399, Accuracy: 47.24%\n",
      "Epoch 184/250, Loss: 1.6415, Accuracy: 47.36%\n",
      "Epoch 185/250, Loss: 1.6434, Accuracy: 47.29%\n",
      "Epoch 186/250, Loss: 1.6456, Accuracy: 47.18%\n",
      "Epoch 187/250, Loss: 1.6475, Accuracy: 47.24%\n",
      "Epoch 188/250, Loss: 1.6497, Accuracy: 47.06%\n",
      "Epoch 189/250, Loss: 1.6509, Accuracy: 47.20%\n",
      "Epoch 190/250, Loss: 1.6542, Accuracy: 47.13%\n",
      "Epoch 191/250, Loss: 1.6559, Accuracy: 47.18%\n",
      "Epoch 192/250, Loss: 1.6578, Accuracy: 47.06%\n",
      "Epoch 193/250, Loss: 1.6598, Accuracy: 47.06%\n",
      "Epoch 194/250, Loss: 1.6612, Accuracy: 47.04%\n",
      "Epoch 195/250, Loss: 1.6639, Accuracy: 46.88%\n",
      "Epoch 196/250, Loss: 1.6664, Accuracy: 46.97%\n",
      "Epoch 197/250, Loss: 1.6678, Accuracy: 46.91%\n",
      "Epoch 198/250, Loss: 1.6696, Accuracy: 46.83%\n",
      "Epoch 199/250, Loss: 1.6722, Accuracy: 46.81%\n",
      "Epoch 200/250, Loss: 1.6739, Accuracy: 46.93%\n",
      "Epoch 201/250, Loss: 1.6755, Accuracy: 46.89%\n",
      "Epoch 202/250, Loss: 1.6781, Accuracy: 46.74%\n",
      "Epoch 203/250, Loss: 1.6794, Accuracy: 46.73%\n",
      "Epoch 204/250, Loss: 1.6812, Accuracy: 46.70%\n",
      "Epoch 205/250, Loss: 1.6839, Accuracy: 46.79%\n",
      "Epoch 206/250, Loss: 1.6849, Accuracy: 46.86%\n",
      "Epoch 207/250, Loss: 1.6880, Accuracy: 46.81%\n",
      "Epoch 208/250, Loss: 1.6893, Accuracy: 46.77%\n",
      "Epoch 209/250, Loss: 1.6913, Accuracy: 46.69%\n",
      "Epoch 210/250, Loss: 1.6931, Accuracy: 46.71%\n",
      "Epoch 211/250, Loss: 1.6957, Accuracy: 46.65%\n",
      "Epoch 212/250, Loss: 1.6975, Accuracy: 46.67%\n",
      "Epoch 213/250, Loss: 1.7000, Accuracy: 46.57%\n",
      "Epoch 214/250, Loss: 1.7016, Accuracy: 46.58%\n",
      "Epoch 215/250, Loss: 1.7033, Accuracy: 46.47%\n",
      "Epoch 216/250, Loss: 1.7055, Accuracy: 46.53%\n",
      "Epoch 217/250, Loss: 1.7073, Accuracy: 46.56%\n",
      "Epoch 218/250, Loss: 1.7094, Accuracy: 46.42%\n",
      "Epoch 219/250, Loss: 1.7118, Accuracy: 46.33%\n",
      "Epoch 220/250, Loss: 1.7138, Accuracy: 46.36%\n",
      "Epoch 221/250, Loss: 1.7168, Accuracy: 46.26%\n",
      "Epoch 222/250, Loss: 1.7184, Accuracy: 46.34%\n",
      "Epoch 223/250, Loss: 1.7199, Accuracy: 46.38%\n",
      "Epoch 224/250, Loss: 1.7218, Accuracy: 46.26%\n",
      "Epoch 225/250, Loss: 1.7243, Accuracy: 46.32%\n",
      "Epoch 226/250, Loss: 1.7271, Accuracy: 46.23%\n",
      "Epoch 227/250, Loss: 1.7295, Accuracy: 46.29%\n",
      "Epoch 228/250, Loss: 1.7318, Accuracy: 46.26%\n",
      "Epoch 229/250, Loss: 1.7336, Accuracy: 46.29%\n",
      "Epoch 230/250, Loss: 1.7357, Accuracy: 46.32%\n",
      "Epoch 231/250, Loss: 1.7375, Accuracy: 46.26%\n",
      "Epoch 232/250, Loss: 1.7405, Accuracy: 46.18%\n",
      "Epoch 233/250, Loss: 1.7425, Accuracy: 46.24%\n",
      "Epoch 234/250, Loss: 1.7447, Accuracy: 46.29%\n",
      "Epoch 235/250, Loss: 1.7482, Accuracy: 46.15%\n",
      "Epoch 236/250, Loss: 1.7501, Accuracy: 46.21%\n",
      "Epoch 237/250, Loss: 1.7518, Accuracy: 46.11%\n",
      "Epoch 238/250, Loss: 1.7542, Accuracy: 46.15%\n",
      "Epoch 239/250, Loss: 1.7573, Accuracy: 46.19%\n",
      "Epoch 240/250, Loss: 1.7591, Accuracy: 46.12%\n",
      "Epoch 241/250, Loss: 1.7622, Accuracy: 45.95%\n",
      "Epoch 242/250, Loss: 1.7640, Accuracy: 46.11%\n",
      "Epoch 243/250, Loss: 1.7664, Accuracy: 46.14%\n",
      "Epoch 244/250, Loss: 1.7691, Accuracy: 46.04%\n",
      "Epoch 245/250, Loss: 1.7718, Accuracy: 45.96%\n",
      "Epoch 246/250, Loss: 1.7730, Accuracy: 45.95%\n",
      "Epoch 247/250, Loss: 1.7760, Accuracy: 45.94%\n",
      "Epoch 248/250, Loss: 1.7784, Accuracy: 45.88%\n",
      "Epoch 249/250, Loss: 1.7804, Accuracy: 45.97%\n",
      "Epoch 250/250, Loss: 1.7833, Accuracy: 45.93%\n",
      "Time to train: 132.07 seconds\n"
     ]
    }
   ],
   "source": [
    "# We import pytorch and torchvision\n",
    "import torchvision, torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# Import numpy\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.5,), (0.5,))  # Perform normalization on GPU if possible\n",
    "])\n",
    "\n",
    "# We load CIFAR-10 dataset\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='data/', train=True, transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='data/', train=False, transform=transform, download=True)\n",
    "\n",
    "# Charger un dataloader with batch size x\n",
    "def get_data_loader(dataset, batch_size):\n",
    "    return torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "def get_batch_format(data_loader):\n",
    "    images_t, labels_t = next(iter(data_loader))\n",
    "    print('images.shape:', images_t.shape)\n",
    "    print('labels.shape:', labels_t.shape)\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim1 = 32, output_dim=10):\n",
    "        super(Network, self).__init__()\n",
    "        self.a = nn.Linear(input_dim, hidden_dim1)\n",
    "        self.b = nn.Linear(hidden_dim1, hidden_dim1)\n",
    "        self.c = nn.Linear(hidden_dim1, hidden_dim1)\n",
    "        self.d = nn.Linear(hidden_dim1, output_dim)\n",
    "        \n",
    "        # We Add non-linearity\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 3, 1)\n",
    "        x1 = self.act(self.a(x))\n",
    "        x2 = self.act(self.b(x1))\n",
    "        x3 = self.act(self.c(x2))\n",
    "        x4 = self.d(x3)\n",
    "        return x4\n",
    "\n",
    "# Fonction accuracy pour calculer le total des bonnes réponses\n",
    "def accuracy(predictions, labels):\n",
    "    _, predicted_labels = torch.max(predictions, 1)\n",
    "    correct = (predicted_labels == labels).sum().item()\n",
    "    return correct / len(labels)\n",
    "\n",
    "# Charger dans un DataLoader le data set de train CIFAR10\n",
    "train_loader = get_data_loader(train_dataset, 128) # On charge par batch\n",
    "# On charge le dataset de testto\n",
    "test_loader = get_data_loader(test_dataset, 10000) # On charge tout le dataset de test\n",
    "# Print the format of the batch\n",
    "get_batch_format(train_loader)\n",
    "\n",
    "# On recupère le device\n",
    "deviceGPU = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# On crée une instance de la classe MyClass\n",
    "modelNet = Network(3*32*32, 32, 10)\n",
    "\n",
    "# On envoie le modèle sur le device\n",
    "modelNet = modelNet.to(deviceGPU)\n",
    "\n",
    "# On crée une fonction de loss\n",
    "lossFn = F.cross_entropy\n",
    "learningRate = 0.0001\n",
    "\n",
    "# On crée un optimiseur\n",
    "opt = torch.optim.Adam(modelNet.parameters(), lr=learningRate, weight_decay=0.0001)\n",
    "\n",
    "def off_load_on_gpu(train_loader, test_loader, device):\n",
    "    train_loader_gpu = [(x.to(device).view(x.shape[0], -1), y.to(device)) for x, y in train_loader]\n",
    "    test_loader_gpu = [(x.to(device).view(x.shape[0], -1), y.to(device)) for x, y in test_loader]\n",
    "    return train_loader_gpu, test_loader_gpu\n",
    "\n",
    "def training_cycle(model, train_loader, device):\n",
    "    model.train()\n",
    "    for x, y in train_loader:\n",
    "        preds = model(x)\n",
    "        loss = lossFn(preds, y)\n",
    "        # Compute gradients\n",
    "        loss.backward()\n",
    "        # Update parameters\n",
    "        opt.step()\n",
    "        # Reset gradients to 0\n",
    "        opt.zero_grad()\n",
    "    \n",
    "def validation_cycle(model, test_loader, epoch, num_epochs, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            preds = model(x)\n",
    "            loss = lossFn(preds, y)\n",
    "            total_loss += loss.item()\n",
    "            total_correct += accuracy(preds, y)\n",
    "\n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    avg_acc = total_correct / len(test_loader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}, Accuracy: {avg_acc * 100:.2f}%\")\n",
    "\n",
    "def fit_one_cycle(model, train_loader, test_loader, epoch, num_epochs, device): \n",
    "    # Training\n",
    "    training_cycle(model, train_loader, device)\n",
    "    \n",
    "    # Validation\n",
    "    validation_cycle(model, test_loader, epoch, num_epochs, device)\n",
    "    \n",
    "# Training loop\n",
    "num_epochs = 50\n",
    "# Time to train\n",
    "time_to_train = time.time()\n",
    "\n",
    "# On charge les données sur le GPU\n",
    "train_loader_gpu, test_loader_gpu = off_load_on_gpu(train_loader, test_loader, deviceGPU)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    fit_one_cycle(modelNet, train_loader_gpu, test_loader_gpu, epoch, num_epochs, deviceGPU)\n",
    "\n",
    "time_to_train = time.time() - time_to_train\n",
    "print(f\"Time to train: {time_to_train:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```text\n",
    "Convolutionnal Network\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "images.shape: torch.Size([128, 3, 32, 32])\n",
      "labels.shape: torch.Size([128])\n",
      "Epoch 1/50, Loss: 1.5867, Accuracy: 42.42%\n",
      "Epoch 2/50, Loss: 1.4441, Accuracy: 47.74%\n",
      "Epoch 3/50, Loss: 1.3621, Accuracy: 51.12%\n",
      "Epoch 4/50, Loss: 1.3019, Accuracy: 53.50%\n",
      "Epoch 5/50, Loss: 1.2501, Accuracy: 55.31%\n",
      "Epoch 6/50, Loss: 1.2048, Accuracy: 57.11%\n",
      "Epoch 7/50, Loss: 1.1648, Accuracy: 58.82%\n",
      "Epoch 8/50, Loss: 1.1294, Accuracy: 59.90%\n",
      "Epoch 9/50, Loss: 1.0989, Accuracy: 60.91%\n",
      "Epoch 10/50, Loss: 1.0711, Accuracy: 61.99%\n",
      "Epoch 11/50, Loss: 1.0452, Accuracy: 63.05%\n",
      "Epoch 12/50, Loss: 1.0228, Accuracy: 63.93%\n",
      "Epoch 13/50, Loss: 1.0036, Accuracy: 64.66%\n",
      "Epoch 14/50, Loss: 0.9865, Accuracy: 65.33%\n",
      "Epoch 15/50, Loss: 0.9702, Accuracy: 65.80%\n",
      "Epoch 16/50, Loss: 0.9560, Accuracy: 66.60%\n",
      "Epoch 17/50, Loss: 0.9424, Accuracy: 67.02%\n",
      "Epoch 18/50, Loss: 0.9302, Accuracy: 67.58%\n",
      "Epoch 19/50, Loss: 0.9190, Accuracy: 67.93%\n",
      "Epoch 20/50, Loss: 0.9095, Accuracy: 68.39%\n",
      "Epoch 21/50, Loss: 0.9005, Accuracy: 68.79%\n",
      "Epoch 22/50, Loss: 0.8915, Accuracy: 69.27%\n",
      "Epoch 23/50, Loss: 0.8850, Accuracy: 69.54%\n",
      "Epoch 24/50, Loss: 0.8792, Accuracy: 69.69%\n",
      "Epoch 25/50, Loss: 0.8729, Accuracy: 69.80%\n",
      "Epoch 26/50, Loss: 0.8659, Accuracy: 70.10%\n",
      "Epoch 27/50, Loss: 0.8603, Accuracy: 70.36%\n",
      "Epoch 28/50, Loss: 0.8547, Accuracy: 70.69%\n",
      "Epoch 29/50, Loss: 0.8491, Accuracy: 70.87%\n",
      "Epoch 30/50, Loss: 0.8449, Accuracy: 71.20%\n",
      "Epoch 31/50, Loss: 0.8399, Accuracy: 71.34%\n",
      "Epoch 32/50, Loss: 0.8362, Accuracy: 71.42%\n",
      "Epoch 33/50, Loss: 0.8333, Accuracy: 71.52%\n",
      "Epoch 34/50, Loss: 0.8303, Accuracy: 71.74%\n",
      "Epoch 35/50, Loss: 0.8269, Accuracy: 71.83%\n",
      "Epoch 36/50, Loss: 0.8258, Accuracy: 72.01%\n",
      "Epoch 37/50, Loss: 0.8231, Accuracy: 72.05%\n",
      "Epoch 38/50, Loss: 0.8224, Accuracy: 72.21%\n",
      "Epoch 39/50, Loss: 0.8206, Accuracy: 72.38%\n",
      "Epoch 40/50, Loss: 0.8191, Accuracy: 72.33%\n",
      "Epoch 41/50, Loss: 0.8182, Accuracy: 72.52%\n",
      "Epoch 42/50, Loss: 0.8184, Accuracy: 72.58%\n",
      "Epoch 43/50, Loss: 0.8177, Accuracy: 72.55%\n",
      "Epoch 44/50, Loss: 0.8184, Accuracy: 72.74%\n",
      "Epoch 45/50, Loss: 0.8192, Accuracy: 72.92%\n",
      "Epoch 46/50, Loss: 0.8208, Accuracy: 73.06%\n",
      "Epoch 47/50, Loss: 0.8219, Accuracy: 73.22%\n",
      "Epoch 48/50, Loss: 0.8253, Accuracy: 73.28%\n",
      "Epoch 49/50, Loss: 0.8284, Accuracy: 73.30%\n",
      "Epoch 50/50, Loss: 0.8314, Accuracy: 73.40%\n",
      "Time to train: 122.93 seconds\n"
     ]
    }
   ],
   "source": [
    "# We import pytorch and torchvision\n",
    "import torchvision, torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# Import numpy\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.5,), (0.5,))  # Perform normalization on GPU if possible\n",
    "])\n",
    "\n",
    "# We load CIFAR-10 dataset\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='data/', train=True, transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='data/', train=False, transform=transform, download=True)\n",
    "\n",
    "# Charger un dataloader with batch size x\n",
    "def get_data_loader(dataset, batch_size):\n",
    "    return torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "def get_batch_format(data_loader):\n",
    "    images_t, labels_t = next(iter(data_loader))\n",
    "    print('images.shape:', images_t.shape)\n",
    "    print('labels.shape:', labels_t.shape)\n",
    "\n",
    "# Fonction accuracy pour calculer le total des bonnes réponses\n",
    "def accuracy(predictions, labels):\n",
    "    _, predicted_labels = torch.max(predictions, 1)\n",
    "    correct = (predicted_labels == labels).sum().item()\n",
    "    return correct / len(labels)\n",
    "\n",
    "# Charger dans un DataLoader le data set de train CIFAR10\n",
    "train_loader = get_data_loader(train_dataset, 128) # On charge par batch\n",
    "# On charge le dataset de testto\n",
    "test_loader = get_data_loader(test_dataset, 10000) # On charge tout le dataset de test\n",
    "# Print the format of the batch\n",
    "get_batch_format(train_loader)\n",
    "\n",
    "# On recupère le device\n",
    "deviceGPU = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# On crée une fonction de loss\n",
    "lossFn = F.cross_entropy\n",
    "learningRate = 0.0001\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 256)\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.act(self.conv1(x)))\n",
    "        x = self.pool(self.act(self.conv2(x)))\n",
    "        x = self.pool(self.act(self.conv3(x)))\n",
    "        x = x.view(-1, 128 * 4 * 4)\n",
    "        x = self.act(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Create an instance of the ConvNet model\n",
    "modelNet = ConvNet().to(deviceGPU)\n",
    "\n",
    "# Create a new optimizer for the ConvNet model\n",
    "opt = torch.optim.Adam(modelNet.parameters(), lr=learningRate, weight_decay=0.0001)\n",
    "\n",
    "def off_load_on_gpu(train_loader, test_loader, device):\n",
    "    train_loader_gpu = [(x.to(device), y.to(device)) for x, y in train_loader]\n",
    "    test_loader_gpu = [(x.to(device), y.to(device)) for x, y in test_loader]\n",
    "    return train_loader_gpu, test_loader_gpu\n",
    "\n",
    "def training_cycle(model, train_loader, device):\n",
    "    model.train()\n",
    "    for x, y in train_loader:\n",
    "        preds = model(x)\n",
    "        loss = lossFn(preds, y)\n",
    "        # Compute gradients\n",
    "        loss.backward()\n",
    "        # Update parameters\n",
    "        opt.step()\n",
    "        # Reset gradients to 0\n",
    "        opt.zero_grad()\n",
    "    \n",
    "def validation_cycle(model, test_loader, epoch, num_epochs, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            preds = model(x)\n",
    "            loss = lossFn(preds, y)\n",
    "            total_loss += loss.item()\n",
    "            total_correct += accuracy(preds, y)\n",
    "\n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    avg_acc = total_correct / len(test_loader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}, Accuracy: {avg_acc * 100:.2f}%\")\n",
    "\n",
    "def fit_one_cycle(model, train_loader, test_loader, epoch, num_epochs, device): \n",
    "    # Training\n",
    "    training_cycle(model, train_loader, device)\n",
    "    \n",
    "    # Validation\n",
    "    validation_cycle(model, test_loader, epoch, num_epochs, device)\n",
    "\n",
    "# Offload data to GPU\n",
    "train_loader_gpu, test_loader_gpu = off_load_on_gpu(train_loader, test_loader, deviceGPU)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 50\n",
    "time_to_train = time.time()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    fit_one_cycle(modelNet, train_loader_gpu, test_loader_gpu, epoch, num_epochs, deviceGPU)\n",
    "\n",
    "time_to_train = time.time() - time_to_train\n",
    "print(f\"Time to train: {time_to_train:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```text\n",
    "Strided Convolutions\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "images.shape: torch.Size([128, 3, 32, 32])\n",
      "labels.shape: torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "# We import pytorch and torchvision\n",
    "import torchvision, torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# Import numpy\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.5,), (0.5,))  # Perform normalization on GPU if possible\n",
    "])\n",
    "\n",
    "# We load CIFAR-10 dataset\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='data/', train=True, transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='data/', train=False, transform=transform, download=True)\n",
    "\n",
    "# Charger un dataloader with batch size x\n",
    "def get_data_loader(dataset, batch_size):\n",
    "    return torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "def get_batch_format(data_loader):\n",
    "    images_t, labels_t = next(iter(data_loader))\n",
    "    print('images.shape:', images_t.shape)\n",
    "    print('labels.shape:', labels_t.shape)\n",
    "\n",
    "# Fonction accuracy pour calculer le total des bonnes réponses\n",
    "def accuracy(predictions, labels):\n",
    "    _, predicted_labels = torch.max(predictions, 1)\n",
    "    correct = (predicted_labels == labels).sum().item()\n",
    "    return correct / len(labels)\n",
    "\n",
    "# Charger dans un DataLoader le data set de train CIFAR10\n",
    "train_loader = get_data_loader(train_dataset, 128) # On charge par batch\n",
    "# On charge le dataset de testto\n",
    "test_loader = get_data_loader(test_dataset, 10000) # On charge tout le dataset de test\n",
    "# Print the format of the batch\n",
    "get_batch_format(train_loader)\n",
    "\n",
    "# On recupère le device\n",
    "deviceGPU = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# On crée une fonction de loss\n",
    "lossFn = F.cross_entropy\n",
    "learningRate = 0.0001\n",
    "  \n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1)  # Stride 2\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1)  # Stride 2\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1)  # Stride 2\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 256)\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.act(self.conv1(x))\n",
    "        x = self.act(self.conv2(x))\n",
    "        x = self.act(self.conv3(x))\n",
    "        x = x.view(-1, 128 * 4 * 4)\n",
    "        x = self.act(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Create an instance of the ConvNet model\n",
    "modelNet = ConvNet().to(deviceGPU)\n",
    "\n",
    "# Create a new optimizer for the ConvNet model\n",
    "opt = torch.optim.Adam(modelNet.parameters(), lr=learningRate, weight_decay=0.0001)\n",
    "\n",
    "def off_load_on_gpu(train_loader, test_loader, device):\n",
    "    train_loader_gpu = [(x.to(device), y.to(device)) for x, y in train_loader]\n",
    "    test_loader_gpu = [(x.to(device), y.to(device)) for x, y in test_loader]\n",
    "    return train_loader_gpu, test_loader_gpu\n",
    "\n",
    "def training_cycle(model, train_loader, device):\n",
    "    model.train()\n",
    "    for x, y in train_loader:\n",
    "        preds = model(x)\n",
    "        loss = lossFn(preds, y)\n",
    "        # Compute gradients\n",
    "        loss.backward()\n",
    "        # Update parameters\n",
    "        opt.step()\n",
    "        # Reset gradients to 0\n",
    "        opt.zero_grad()\n",
    "    \n",
    "def validation_cycle(model, test_loader, epoch, num_epochs, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            preds = model(x)\n",
    "            loss = lossFn(preds, y)\n",
    "            total_loss += loss.item()\n",
    "            total_correct += accuracy(preds, y)\n",
    "\n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    avg_acc = total_correct / len(test_loader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}, Accuracy: {avg_acc * 100:.2f}%\")\n",
    "\n",
    "def fit_one_cycle(model, train_loader, test_loader, epoch, num_epochs, device): \n",
    "    # Training\n",
    "    training_cycle(model, train_loader, device)\n",
    "    \n",
    "    # Validation\n",
    "    validation_cycle(model, test_loader, epoch, num_epochs, device)\n",
    "\n",
    "# Offload data to GPU\n",
    "train_loader_gpu, test_loader_gpu = off_load_on_gpu(train_loader, test_loader, deviceGPU)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 50\n",
    "time_to_train = time.time()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    fit_one_cycle(modelNet, train_loader_gpu, test_loader_gpu, epoch, num_epochs, deviceGPU)\n",
    "\n",
    "time_to_train = time.time() - time_to_train\n",
    "print(f\"Time to train: {time_to_train:.2f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
