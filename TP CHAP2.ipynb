{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```text\n",
    "Non Linear Network\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We import pytorch and torchvision\n",
    "import torchvision, torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# Import numpy\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.5,), (0.5,))  # Perform normalization on GPU if possible\n",
    "])\n",
    "\n",
    "# We load CIFAR-10 dataset\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='data/', train=True, transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='data/', train=False, transform=transform, download=True)\n",
    "\n",
    "# Charger un dataloader with batch size x\n",
    "def get_data_loader(dataset, batch_size):\n",
    "    return torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "def get_batch_format(data_loader):\n",
    "    images_t, labels_t = next(iter(data_loader))\n",
    "    print('images.shape:', images_t.shape)\n",
    "    print('labels.shape:', labels_t.shape)\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim1 = 32, output_dim=10):\n",
    "        super(Network, self).__init__()\n",
    "        self.a = nn.Linear(input_dim, hidden_dim1)\n",
    "        self.b = nn.Linear(hidden_dim1, hidden_dim1)\n",
    "        self.c = nn.Linear(hidden_dim1, hidden_dim1)\n",
    "        self.d = nn.Linear(hidden_dim1, output_dim)\n",
    "        \n",
    "        # We Add non-linearity\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 3, 1)\n",
    "        x1 = self.act(self.a(x))\n",
    "        x2 = self.act(self.b(x1))\n",
    "        x3 = self.act(self.c(x2))\n",
    "        x4 = self.d(x3)\n",
    "        return x4\n",
    "\n",
    "# Fonction accuracy pour calculer le total des bonnes réponses\n",
    "def accuracy(predictions, labels):\n",
    "    _, predicted_labels = torch.max(predictions, 1)\n",
    "    correct = (predicted_labels == labels).sum().item()\n",
    "    return correct / len(labels)\n",
    "\n",
    "# Charger dans un DataLoader le data set de train CIFAR10\n",
    "train_loader = get_data_loader(train_dataset, 128) # On charge par batch\n",
    "# On charge le dataset de testto\n",
    "test_loader = get_data_loader(test_dataset, 10000) # On charge tout le dataset de test\n",
    "# Print the format of the batch\n",
    "get_batch_format(train_loader)\n",
    "\n",
    "# On recupère le device\n",
    "deviceGPU = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# On crée une instance de la classe MyClass\n",
    "modelNet = Network(3*32*32, 32, 10)\n",
    "\n",
    "# On envoie le modèle sur le device\n",
    "modelNet = modelNet.to(deviceGPU)\n",
    "\n",
    "# On crée une fonction de loss\n",
    "lossFn = F.cross_entropy\n",
    "learningRate = 0.0001\n",
    "\n",
    "# On crée un optimiseur\n",
    "opt = torch.optim.Adam(modelNet.parameters(), lr=learningRate, weight_decay=0.0001)\n",
    "\n",
    "def off_load_on_gpu(train_loader, test_loader, device):\n",
    "    train_loader_gpu = [(x.to(device).view(x.shape[0], -1), y.to(device)) for x, y in train_loader]\n",
    "    test_loader_gpu = [(x.to(device).view(x.shape[0], -1), y.to(device)) for x, y in test_loader]\n",
    "    return train_loader_gpu, test_loader_gpu\n",
    "\n",
    "def training_cycle(model, train_loader, device):\n",
    "    model.train()\n",
    "    for x, y in train_loader:\n",
    "        preds = model(x)\n",
    "        loss = lossFn(preds, y)\n",
    "        # Compute gradients\n",
    "        loss.backward()\n",
    "        # Update parameters\n",
    "        opt.step()\n",
    "        # Reset gradients to 0\n",
    "        opt.zero_grad()\n",
    "    \n",
    "def validation_cycle(model, test_loader, epoch, num_epochs, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            preds = model(x)\n",
    "            loss = lossFn(preds, y)\n",
    "            total_loss += loss.item()\n",
    "            total_correct += accuracy(preds, y)\n",
    "\n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    avg_acc = total_correct / len(test_loader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}, Accuracy: {avg_acc * 100:.2f}%\")\n",
    "\n",
    "def fit_one_cycle(model, train_loader, test_loader, epoch, num_epochs, device): \n",
    "    # Training\n",
    "    training_cycle(model, train_loader, device)\n",
    "    \n",
    "    # Validation\n",
    "    validation_cycle(model, test_loader, epoch, num_epochs, device)\n",
    "    \n",
    "# Training loop\n",
    "num_epochs = 50\n",
    "# Time to train\n",
    "time_to_train = time.time()\n",
    "\n",
    "# On charge les données sur le GPU\n",
    "train_loader_gpu, test_loader_gpu = off_load_on_gpu(train_loader, test_loader, deviceGPU)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    fit_one_cycle(modelNet, train_loader_gpu, test_loader_gpu, epoch, num_epochs, deviceGPU)\n",
    "\n",
    "time_to_train = time.time() - time_to_train\n",
    "print(f\"Time to train: {time_to_train:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```text\n",
    "Convolutionnal Network\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We import pytorch and torchvision\n",
    "import torchvision, torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# Import numpy\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.5,), (0.5,))  # Perform normalization on GPU if possible\n",
    "])\n",
    "\n",
    "# We load CIFAR-10 dataset\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='data/', train=True, transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='data/', train=False, transform=transform, download=True)\n",
    "\n",
    "# Charger un dataloader with batch size x\n",
    "def get_data_loader(dataset, batch_size):\n",
    "    return torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "def get_batch_format(data_loader):\n",
    "    images_t, labels_t = next(iter(data_loader))\n",
    "    print('images.shape:', images_t.shape)\n",
    "    print('labels.shape:', labels_t.shape)\n",
    "\n",
    "# Fonction accuracy pour calculer le total des bonnes réponses\n",
    "def accuracy(predictions, labels):\n",
    "    _, predicted_labels = torch.max(predictions, 1)\n",
    "    correct = (predicted_labels == labels).sum().item()\n",
    "    return correct / len(labels)\n",
    "\n",
    "# Charger dans un DataLoader le data set de train CIFAR10\n",
    "train_loader = get_data_loader(train_dataset, 128) # On charge par batch\n",
    "# On charge le dataset de testto\n",
    "test_loader = get_data_loader(test_dataset, 10000) # On charge tout le dataset de test\n",
    "# Print the format of the batch\n",
    "get_batch_format(train_loader)\n",
    "\n",
    "# On recupère le device\n",
    "deviceGPU = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# On crée une fonction de loss\n",
    "lossFn = F.cross_entropy\n",
    "learningRate = 0.0001\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 256)\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.act(self.conv1(x)))\n",
    "        x = self.pool(self.act(self.conv2(x)))\n",
    "        x = self.pool(self.act(self.conv3(x)))\n",
    "        x = x.view(-1, 128 * 4 * 4)\n",
    "        x = self.act(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Create an instance of the ConvNet model\n",
    "modelNet = ConvNet().to(deviceGPU)\n",
    "\n",
    "# Create a new optimizer for the ConvNet model\n",
    "opt = torch.optim.Adam(modelNet.parameters(), lr=learningRate, weight_decay=0.0001)\n",
    "\n",
    "def off_load_on_gpu(train_loader, test_loader, device):\n",
    "    train_loader_gpu = [(x.to(device), y.to(device)) for x, y in train_loader]\n",
    "    test_loader_gpu = [(x.to(device), y.to(device)) for x, y in test_loader]\n",
    "    return train_loader_gpu, test_loader_gpu\n",
    "\n",
    "def training_cycle(model, train_loader, device):\n",
    "    model.train()\n",
    "    for x, y in train_loader:\n",
    "        preds = model(x)\n",
    "        loss = lossFn(preds, y)\n",
    "        # Compute gradients\n",
    "        loss.backward()\n",
    "        # Update parameters\n",
    "        opt.step()\n",
    "        # Reset gradients to 0\n",
    "        opt.zero_grad()\n",
    "    \n",
    "def validation_cycle(model, test_loader, epoch, num_epochs, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            preds = model(x)\n",
    "            loss = lossFn(preds, y)\n",
    "            total_loss += loss.item()\n",
    "            total_correct += accuracy(preds, y)\n",
    "\n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    avg_acc = total_correct / len(test_loader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}, Accuracy: {avg_acc * 100:.2f}%\")\n",
    "\n",
    "def fit_one_cycle(model, train_loader, test_loader, epoch, num_epochs, device): \n",
    "    # Training\n",
    "    training_cycle(model, train_loader, device)\n",
    "    \n",
    "    # Validation\n",
    "    validation_cycle(model, test_loader, epoch, num_epochs, device)\n",
    "\n",
    "# Offload data to GPU\n",
    "train_loader_gpu, test_loader_gpu = off_load_on_gpu(train_loader, test_loader, deviceGPU)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 50\n",
    "time_to_train = time.time()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    fit_one_cycle(modelNet, train_loader_gpu, test_loader_gpu, epoch, num_epochs, deviceGPU)\n",
    "\n",
    "time_to_train = time.time() - time_to_train\n",
    "print(f\"Time to train: {time_to_train:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```text\n",
    "Strided Convolutions\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We import pytorch and torchvision\n",
    "import torchvision, torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# Import numpy\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.5,), (0.5,))  # Perform normalization on GPU if possible\n",
    "])\n",
    "\n",
    "# We load CIFAR-10 dataset\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='data/', train=True, transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='data/', train=False, transform=transform, download=True)\n",
    "\n",
    "# Charger un dataloader with batch size x\n",
    "def get_data_loader(dataset, batch_size):\n",
    "    return torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "def get_batch_format(data_loader):\n",
    "    images_t, labels_t = next(iter(data_loader))\n",
    "    print('images.shape:', images_t.shape)\n",
    "    print('labels.shape:', labels_t.shape)\n",
    "\n",
    "# Fonction accuracy pour calculer le total des bonnes réponses\n",
    "def accuracy(predictions, labels):\n",
    "    _, predicted_labels = torch.max(predictions, 1)\n",
    "    correct = (predicted_labels == labels).sum().item()\n",
    "    return correct / len(labels)\n",
    "\n",
    "# Charger dans un DataLoader le data set de train CIFAR10\n",
    "train_loader = get_data_loader(train_dataset, 128) # On charge par batch\n",
    "# On charge le dataset de testto\n",
    "test_loader = get_data_loader(test_dataset, 10000) # On charge tout le dataset de test\n",
    "# Print the format of the batch\n",
    "get_batch_format(train_loader)\n",
    "\n",
    "# On recupère le device\n",
    "deviceGPU = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# On crée une fonction de loss\n",
    "lossFn = F.cross_entropy\n",
    "learningRate = 0.0001\n",
    "  \n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1)  # Stride 2\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1)  # Stride 2\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1)  # Stride 2\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 256)\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.act(self.conv1(x))\n",
    "        x = self.act(self.conv2(x))\n",
    "        x = self.act(self.conv3(x))\n",
    "        x = x.view(-1, 128 * 4 * 4)\n",
    "        x = self.act(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Create an instance of the ConvNet model\n",
    "modelNet = ConvNet().to(deviceGPU)\n",
    "\n",
    "# Create a new optimizer for the ConvNet model\n",
    "opt = torch.optim.Adam(modelNet.parameters(), lr=learningRate, weight_decay=0.0001)\n",
    "\n",
    "def off_load_on_gpu(train_loader, test_loader, device):\n",
    "    train_loader_gpu = [(x.to(device), y.to(device)) for x, y in train_loader]\n",
    "    test_loader_gpu = [(x.to(device), y.to(device)) for x, y in test_loader]\n",
    "    return train_loader_gpu, test_loader_gpu\n",
    "\n",
    "def training_cycle(model, train_loader, device):\n",
    "    model.train()\n",
    "    for x, y in train_loader:\n",
    "        preds = model(x)\n",
    "        loss = lossFn(preds, y)\n",
    "        # Compute gradients\n",
    "        loss.backward()\n",
    "        # Update parameters\n",
    "        opt.step()\n",
    "        # Reset gradients to 0\n",
    "        opt.zero_grad()\n",
    "    \n",
    "def validation_cycle(model, test_loader, epoch, num_epochs, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            preds = model(x)\n",
    "            loss = lossFn(preds, y)\n",
    "            total_loss += loss.item()\n",
    "            total_correct += accuracy(preds, y)\n",
    "\n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    avg_acc = total_correct / len(test_loader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}, Accuracy: {avg_acc * 100:.2f}%\")\n",
    "\n",
    "def fit_one_cycle(model, train_loader, test_loader, epoch, num_epochs, device): \n",
    "    # Training\n",
    "    training_cycle(model, train_loader, device)\n",
    "    \n",
    "    # Validation\n",
    "    validation_cycle(model, test_loader, epoch, num_epochs, device)\n",
    "\n",
    "# Offload data to GPU\n",
    "train_loader_gpu, test_loader_gpu = off_load_on_gpu(train_loader, test_loader, deviceGPU)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 50\n",
    "time_to_train = time.time()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    fit_one_cycle(modelNet, train_loader_gpu, test_loader_gpu, epoch, num_epochs, deviceGPU)\n",
    "\n",
    "time_to_train = time.time() - time_to_train\n",
    "print(f\"Time to train: {time_to_train:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```text\n",
    "Convolutionnal Network (With Residuals Connections)\n",
    "```\n",
    "\n",
    "### Pourquoi n'aurait-on pas pu le faire avec une convolution à stride ?\n",
    "\n",
    "Les convolutions avec stride modifient la taille spatiale (hauteur et largeur) du tenseur d'entrée. Cela signifie que la taille du tenseur de sortie de la convolution ne correspondra pas à la taille du tenseur d'entrée, ce qui rend impossible l'addition directe des tenseurs dans une connexion résiduelle. Les connexions résiduelles nécessitent que les tenseurs aient les mêmes dimensions pour pouvoir les additionner. \n",
    "\n",
    "En utilisant `MaxPool` avec stride, nous réduisons la taille spatiale de manière contrôlée après avoir ajouté la connexion résiduelle, ce qui permet de maintenir la compatibilité des dimensions pour l'addition.\n",
    "\n",
    "Similar code found with 2 license types\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We import pytorch and torchvision\n",
    "import torchvision, torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# Import numpy\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.5,), (0.5,))  # Perform normalization on GPU if possible\n",
    "])\n",
    "\n",
    "# We load CIFAR-10 dataset\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='data/', train=True, transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='data/', train=False, transform=transform, download=True)\n",
    "\n",
    "# Charger un dataloader with batch size x\n",
    "def get_data_loader(dataset, batch_size):\n",
    "    return torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "def get_batch_format(data_loader):\n",
    "    images_t, labels_t = next(iter(data_loader))\n",
    "    print('images.shape:', images_t.shape)\n",
    "    print('labels.shape:', labels_t.shape)\n",
    "\n",
    "# Fonction accuracy pour calculer le total des bonnes réponses\n",
    "def accuracy(predictions, labels):\n",
    "    _, predicted_labels = torch.max(predictions, 1)\n",
    "    correct = (predicted_labels == labels).sum().item()\n",
    "    return correct / len(labels)\n",
    "\n",
    "# Charger dans un DataLoader le data set de train CIFAR10\n",
    "train_loader = get_data_loader(train_dataset, 128) # On charge par batch\n",
    "# On charge le dataset de testto\n",
    "test_loader = get_data_loader(test_dataset, 10000) # On charge tout le dataset de test\n",
    "# Print the format of the batch\n",
    "get_batch_format(train_loader)\n",
    "\n",
    "# On recupère le device\n",
    "deviceGPU = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# On crée une fonction de loss\n",
    "lossFn = F.cross_entropy\n",
    "learningRate = 0.0001\n",
    "\n",
    "class ConvNetResidual(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNetResidual, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 256)\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "        self.act = nn.ReLU(inplace=False)  # Out-of-place activation\n",
    "\n",
    "        # 1x1 convolutions for residuals\n",
    "        self.res_conv1 = nn.Conv2d(3, 32, kernel_size=1, stride=1, padding=0)\n",
    "        self.res_conv2 = nn.Conv2d(32, 64, kernel_size=1, stride=1, padding=0)\n",
    "        self.res_conv3 = nn.Conv2d(64, 128, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # First convolution + residual\n",
    "        residual = self.res_conv1(x)\n",
    "        x = self.act(self.conv1(x))\n",
    "        x = x + residual  # Out-of-place addition\n",
    "        x = self.pool(x)\n",
    "\n",
    "        # Second convolution + residual\n",
    "        residual = self.res_conv2(x)\n",
    "        x = self.act(self.conv2(x))\n",
    "        x = x + residual  # Out-of-place addition\n",
    "        x = self.pool(x)\n",
    "\n",
    "        # Third convolution + residual\n",
    "        residual = self.res_conv3(x)\n",
    "        x = self.act(self.conv3(x))\n",
    "        x = x + residual  # Out-of-place addition\n",
    "        x = self.pool(x)\n",
    "\n",
    "        # Flatten and pass through fully connected layers\n",
    "        x = x.view(-1, 128 * 4 * 4)\n",
    "        x = self.act(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Replace the previous model with the residual one\n",
    "modelNet = ConvNetResidual().to(deviceGPU)\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "# Create a new optimizer for the ConvNet model\n",
    "opt = torch.optim.Adam(modelNet.parameters(), lr=learningRate, weight_decay=0.0001)\n",
    "\n",
    "def off_load_on_gpu(train_loader, test_loader, device):\n",
    "    train_loader_gpu = [(x.to(device), y.to(device)) for x, y in train_loader]\n",
    "    test_loader_gpu = [(x.to(device), y.to(device)) for x, y in test_loader]\n",
    "    return train_loader_gpu, test_loader_gpu\n",
    "\n",
    "def training_cycle(model, train_loader, device):\n",
    "    model.train()\n",
    "    for x, y in train_loader:\n",
    "        preds = model(x)\n",
    "        loss = lossFn(preds, y)\n",
    "        # Compute gradients\n",
    "        loss.backward()\n",
    "        # Update parameters\n",
    "        opt.step()\n",
    "        # Reset gradients to 0\n",
    "        opt.zero_grad()\n",
    "    \n",
    "def validation_cycle(model, test_loader, epoch, num_epochs, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            preds = model(x)\n",
    "            loss = lossFn(preds, y)\n",
    "            total_loss += loss.item()\n",
    "            total_correct += accuracy(preds, y)\n",
    "\n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    avg_acc = total_correct / len(test_loader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}, Accuracy: {avg_acc * 100:.2f}%\")\n",
    "\n",
    "def fit_one_cycle(model, train_loader, test_loader, epoch, num_epochs, device): \n",
    "    # Training\n",
    "    training_cycle(model, train_loader, device)\n",
    "    \n",
    "    # Validation\n",
    "    validation_cycle(model, test_loader, epoch, num_epochs, device)\n",
    "\n",
    "# Offload data to GPU\n",
    "train_loader_gpu, test_loader_gpu = off_load_on_gpu(train_loader, test_loader, deviceGPU)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 50\n",
    "time_to_train = time.time()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    fit_one_cycle(modelNet, train_loader_gpu, test_loader_gpu, epoch, num_epochs, deviceGPU)\n",
    "\n",
    "time_to_train = time.time() - time_to_train\n",
    "print(f\"Time to train: {time_to_train:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```txt\n",
    "Convolutionnal Network (With Batch Normalization)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "images.shape: torch.Size([128, 3, 32, 32])\n",
      "labels.shape: torch.Size([128])\n",
      "Epoch 1/50, Loss: 1.1635, Accuracy: 59.01%\n",
      "Epoch 2/50, Loss: 1.0136, Accuracy: 64.29%\n",
      "Epoch 3/50, Loss: 0.9374, Accuracy: 66.94%\n",
      "Epoch 4/50, Loss: 0.8843, Accuracy: 68.80%\n",
      "Epoch 5/50, Loss: 0.8491, Accuracy: 70.33%\n",
      "Epoch 6/50, Loss: 0.8289, Accuracy: 71.14%\n",
      "Epoch 7/50, Loss: 0.8164, Accuracy: 71.71%\n",
      "Epoch 8/50, Loss: 0.8094, Accuracy: 72.16%\n",
      "Epoch 9/50, Loss: 0.8060, Accuracy: 72.40%\n",
      "Epoch 10/50, Loss: 0.8111, Accuracy: 72.35%\n",
      "Epoch 11/50, Loss: 0.8177, Accuracy: 72.35%\n",
      "Epoch 12/50, Loss: 0.8271, Accuracy: 72.19%\n",
      "Epoch 13/50, Loss: 0.8421, Accuracy: 72.12%\n",
      "Epoch 14/50, Loss: 0.8529, Accuracy: 72.21%\n",
      "Epoch 15/50, Loss: 0.8715, Accuracy: 71.96%\n",
      "Epoch 16/50, Loss: 0.8835, Accuracy: 72.16%\n",
      "Epoch 17/50, Loss: 0.8991, Accuracy: 72.11%\n",
      "Epoch 18/50, Loss: 0.9135, Accuracy: 72.37%\n",
      "Epoch 19/50, Loss: 0.9331, Accuracy: 72.55%\n",
      "Epoch 20/50, Loss: 0.9702, Accuracy: 72.26%\n",
      "Epoch 21/50, Loss: 1.0028, Accuracy: 72.15%\n",
      "Epoch 22/50, Loss: 1.0299, Accuracy: 72.28%\n",
      "Epoch 23/50, Loss: 1.0553, Accuracy: 72.49%\n",
      "Epoch 24/50, Loss: 1.0748, Accuracy: 72.54%\n",
      "Epoch 25/50, Loss: 1.1201, Accuracy: 72.51%\n",
      "Epoch 26/50, Loss: 1.1812, Accuracy: 71.72%\n",
      "Epoch 27/50, Loss: 1.2364, Accuracy: 71.31%\n",
      "Epoch 28/50, Loss: 1.2668, Accuracy: 71.13%\n",
      "Epoch 29/50, Loss: 1.2476, Accuracy: 71.52%\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import torchvision, torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Define the transform\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.5,), (0.5,))  # Normalize on GPU if possible\n",
    "])\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='data/', train=True, transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='data/', train=False, transform=transform, download=True)\n",
    "\n",
    "# Function to create DataLoader\n",
    "def get_data_loader(dataset, batch_size):\n",
    "    return torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "# Display batch format\n",
    "def get_batch_format(data_loader):\n",
    "    images_t, labels_t = next(iter(data_loader))\n",
    "    print('images.shape:', images_t.shape)\n",
    "    print('labels.shape:', labels_t.shape)\n",
    "\n",
    "# Accuracy function\n",
    "def accuracy(predictions, labels):\n",
    "    _, predicted_labels = torch.max(predictions, 1)\n",
    "    correct = (predicted_labels == labels).sum().item()\n",
    "    return correct / len(labels)\n",
    "\n",
    "# Load DataLoaders\n",
    "train_loader = get_data_loader(train_dataset, 128)\n",
    "test_loader = get_data_loader(test_dataset, 10000)\n",
    "get_batch_format(train_loader)\n",
    "\n",
    "# Set device\n",
    "deviceGPU = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# Loss function and learning rate\n",
    "lossFn = F.cross_entropy\n",
    "learningRate = 0.0001\n",
    "\n",
    "# Define the custom MyConv class\n",
    "class MyConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, activation=nn.ReLU(inplace=False)):\n",
    "        super(MyConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.act = activation\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.act(x)\n",
    "        return x\n",
    "\n",
    "# Define the ConvNetResidual model using MyConv\n",
    "class ConvNetResidual(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNetResidual, self).__init__()\n",
    "        self.conv1 = MyConv(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = MyConv(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = MyConv(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 256)\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "\n",
    "        # Residual connections\n",
    "        self.res_conv1 = nn.Conv2d(3, 32, kernel_size=1, stride=1, padding=0)\n",
    "        self.res_conv2 = nn.Conv2d(32, 64, kernel_size=1, stride=1, padding=0)\n",
    "        self.res_conv3 = nn.Conv2d(64, 128, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = self.res_conv1(x)\n",
    "        x = self.conv1(x)\n",
    "        x = x + residual\n",
    "        x = self.pool(x)\n",
    "\n",
    "        residual = self.res_conv2(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x + residual\n",
    "        x = self.pool(x)\n",
    "\n",
    "        residual = self.res_conv3(x)\n",
    "        x = self.conv3(x)\n",
    "        x = x + residual\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = x.view(-1, 128 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the model\n",
    "modelNet = ConvNetResidual().to(deviceGPU)\n",
    "\n",
    "# Optimizer\n",
    "opt = torch.optim.Adam(modelNet.parameters(), lr=learningRate, weight_decay=0.0001)\n",
    "\n",
    "# Offload data to GPU\n",
    "def off_load_on_gpu(train_loader, test_loader, device):\n",
    "    train_loader_gpu = [(x.to(device), y.to(device)) for x, y in train_loader]\n",
    "    test_loader_gpu = [(x.to(device), y.to(device)) for x, y in test_loader]\n",
    "    return train_loader_gpu, test_loader_gpu\n",
    "\n",
    "# Training cycle\n",
    "def training_cycle(model, train_loader, device):\n",
    "    model.train()\n",
    "    for x, y in train_loader:\n",
    "        preds = model(x)\n",
    "        loss = lossFn(preds, y)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "# Validation cycle\n",
    "def validation_cycle(model, test_loader, epoch, num_epochs, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            preds = model(x)\n",
    "            loss = lossFn(preds, y)\n",
    "            total_loss += loss.item()\n",
    "            total_correct += accuracy(preds, y)\n",
    "\n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    avg_acc = total_correct / len(test_loader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}, Accuracy: {avg_acc * 100:.2f}%\")\n",
    "\n",
    "# Training and validation for one epoch\n",
    "def fit_one_cycle(model, train_loader, test_loader, epoch, num_epochs, device): \n",
    "    training_cycle(model, train_loader, device)\n",
    "    validation_cycle(model, test_loader, epoch, num_epochs, device)\n",
    "\n",
    "# Load data onto GPU\n",
    "train_loader_gpu, test_loader_gpu = off_load_on_gpu(train_loader, test_loader, deviceGPU)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 50\n",
    "time_to_train = time.time()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    fit_one_cycle(modelNet, train_loader_gpu, test_loader_gpu, epoch, num_epochs, deviceGPU)\n",
    "\n",
    "time_to_train = time.time() - time_to_train\n",
    "print(f\"Time to train: {time_to_train:.2f} seconds\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
