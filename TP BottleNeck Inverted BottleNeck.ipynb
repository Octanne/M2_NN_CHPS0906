{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```text\n",
    "Normal\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import torchvision, torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Define the transform\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.5,), (0.5,))  # Normalize on GPU if possible\n",
    "])\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='data/', train=True, transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='data/', train=False, transform=transform, download=True)\n",
    "\n",
    "# Function to create DataLoader\n",
    "def get_data_loader(dataset, batch_size):\n",
    "    return torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "# Display batch format\n",
    "def get_batch_format(data_loader):\n",
    "    images_t, labels_t = next(iter(data_loader))\n",
    "    print('images.shape:', images_t.shape)\n",
    "    print('labels.shape:', labels_t.shape)\n",
    "\n",
    "# Accuracy function\n",
    "def accuracy(predictions, labels):\n",
    "    _, predicted_labels = torch.max(predictions, 1)\n",
    "    correct = (predicted_labels == labels).sum().item()\n",
    "    return correct / len(labels)\n",
    "\n",
    "# Load DataLoaders\n",
    "train_loader = get_data_loader(train_dataset, 128)\n",
    "test_loader = get_data_loader(test_dataset, 10000)\n",
    "get_batch_format(train_loader)\n",
    "\n",
    "# Set device\n",
    "deviceGPU = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# Loss function and learning rate\n",
    "lossFn = F.cross_entropy\n",
    "learningRate = 0.0001\n",
    "\n",
    "# Define the custom MyConv class\n",
    "class MyConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, activation=nn.ReLU(inplace=False)):\n",
    "        super(MyConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.act = activation\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.act(x)\n",
    "        return x\n",
    "\n",
    "# Define the ConvNetResidual model using MyConv\n",
    "class ConvNetResidual(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNetResidual, self).__init__()\n",
    "        self.conv1 = MyConv(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = MyConv(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = MyConv(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 256)\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "\n",
    "        # Residual connections\n",
    "        self.res_conv1 = nn.Conv2d(3, 32, kernel_size=1, stride=1, padding=0)\n",
    "        self.res_conv2 = nn.Conv2d(32, 64, kernel_size=1, stride=1, padding=0)\n",
    "        self.res_conv3 = nn.Conv2d(64, 128, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = self.res_conv1(x)\n",
    "        x = self.conv1(x)\n",
    "        x = x + residual\n",
    "        x = self.pool(x)\n",
    "\n",
    "        residual = self.res_conv2(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x + residual\n",
    "        x = self.pool(x)\n",
    "\n",
    "        residual = self.res_conv3(x)\n",
    "        x = self.conv3(x)\n",
    "        x = x + residual\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = x.view(-1, 128 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the model\n",
    "modelNet = ConvNetResidual().to(deviceGPU)\n",
    "\n",
    "# Optimizer\n",
    "opt = torch.optim.Adam(modelNet.parameters(), lr=learningRate, weight_decay=0.0001)\n",
    "\n",
    "# Offload data to GPU\n",
    "def off_load_on_gpu(train_loader, test_loader, device):\n",
    "    train_loader_gpu = [(x.to(device), y.to(device)) for x, y in train_loader]\n",
    "    test_loader_gpu = [(x.to(device), y.to(device)) for x, y in test_loader]\n",
    "    return train_loader_gpu, test_loader_gpu\n",
    "\n",
    "# Training cycle\n",
    "def training_cycle(model, train_loader, device):\n",
    "    model.train()\n",
    "    for x, y in train_loader:\n",
    "        preds = model(x)\n",
    "        loss = lossFn(preds, y)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "# Validation cycle\n",
    "def validation_cycle(model, test_loader, epoch, num_epochs, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            preds = model(x)\n",
    "            loss = lossFn(preds, y)\n",
    "            total_loss += loss.item()\n",
    "            total_correct += accuracy(preds, y)\n",
    "\n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    avg_acc = total_correct / len(test_loader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}, Accuracy: {avg_acc * 100:.2f}%\")\n",
    "\n",
    "# Training and validation for one epoch\n",
    "def fit_one_cycle(model, train_loader, test_loader, epoch, num_epochs, device): \n",
    "    training_cycle(model, train_loader, device)\n",
    "    validation_cycle(model, test_loader, epoch, num_epochs, device)\n",
    "\n",
    "# Load data onto GPU\n",
    "train_loader_gpu, test_loader_gpu = off_load_on_gpu(train_loader, test_loader, deviceGPU)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 50\n",
    "time_to_train = time.time()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    fit_one_cycle(modelNet, train_loader_gpu, test_loader_gpu, epoch, num_epochs, deviceGPU)\n",
    "\n",
    "time_to_train = time.time() - time_to_train\n",
    "print(f\"Time to train: {time_to_train:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```text\n",
    "Bottleneck Block: Reduces, maintains, and restores the information.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch 1/50, Train Loss: 1.6378, Val Loss: 1.4811, Val Accuracy: 47.55%\n",
      "Epoch 2/50, Train Loss: 1.2066, Val Loss: 1.2412, Val Accuracy: 56.93%\n",
      "Epoch 3/50, Train Loss: 0.9693, Val Loss: 1.0040, Val Accuracy: 65.24%\n",
      "Epoch 4/50, Train Loss: 0.8200, Val Loss: 0.8809, Val Accuracy: 69.58%\n",
      "Epoch 5/50, Train Loss: 0.7159, Val Loss: 0.8805, Val Accuracy: 70.30%\n",
      "Epoch 6/50, Train Loss: 0.6284, Val Loss: 0.8017, Val Accuracy: 72.64%\n",
      "Epoch 7/50, Train Loss: 0.5611, Val Loss: 0.7893, Val Accuracy: 74.37%\n",
      "Epoch 8/50, Train Loss: 0.5005, Val Loss: 0.7202, Val Accuracy: 75.80%\n",
      "Epoch 9/50, Train Loss: 0.4475, Val Loss: 0.7595, Val Accuracy: 74.35%\n",
      "Epoch 10/50, Train Loss: 0.4006, Val Loss: 0.7611, Val Accuracy: 75.84%\n",
      "Epoch 11/50, Train Loss: 0.3606, Val Loss: 1.0420, Val Accuracy: 68.01%\n",
      "Epoch 12/50, Train Loss: 0.3221, Val Loss: 0.8220, Val Accuracy: 74.86%\n",
      "Epoch 13/50, Train Loss: 0.2896, Val Loss: 0.7572, Val Accuracy: 76.66%\n",
      "Epoch 14/50, Train Loss: 0.2587, Val Loss: 0.8240, Val Accuracy: 76.40%\n",
      "Epoch 15/50, Train Loss: 0.2370, Val Loss: 0.8160, Val Accuracy: 76.67%\n",
      "Epoch 16/50, Train Loss: 0.2112, Val Loss: 0.8565, Val Accuracy: 75.47%\n",
      "Epoch 17/50, Train Loss: 0.1965, Val Loss: 0.8301, Val Accuracy: 76.97%\n",
      "Epoch 18/50, Train Loss: 0.1714, Val Loss: 0.8886, Val Accuracy: 76.66%\n",
      "Epoch 19/50, Train Loss: 0.1606, Val Loss: 0.8572, Val Accuracy: 76.66%\n",
      "Epoch 20/50, Train Loss: 0.1456, Val Loss: 0.8413, Val Accuracy: 78.09%\n",
      "Epoch 21/50, Train Loss: 0.1415, Val Loss: 0.9298, Val Accuracy: 76.09%\n",
      "Epoch 22/50, Train Loss: 0.1336, Val Loss: 0.9483, Val Accuracy: 76.86%\n",
      "Epoch 23/50, Train Loss: 0.1340, Val Loss: 0.9589, Val Accuracy: 76.41%\n",
      "Epoch 24/50, Train Loss: 0.1210, Val Loss: 0.9956, Val Accuracy: 75.55%\n",
      "Epoch 25/50, Train Loss: 0.1133, Val Loss: 0.9940, Val Accuracy: 75.59%\n",
      "Epoch 26/50, Train Loss: 0.1141, Val Loss: 0.9719, Val Accuracy: 76.97%\n",
      "Epoch 27/50, Train Loss: 0.1064, Val Loss: 0.9233, Val Accuracy: 77.95%\n",
      "Epoch 28/50, Train Loss: 0.1039, Val Loss: 0.9457, Val Accuracy: 77.64%\n",
      "Epoch 29/50, Train Loss: 0.1059, Val Loss: 0.9828, Val Accuracy: 76.91%\n",
      "Epoch 30/50, Train Loss: 0.0988, Val Loss: 1.0032, Val Accuracy: 76.37%\n",
      "Epoch 31/50, Train Loss: 0.0937, Val Loss: 0.9659, Val Accuracy: 77.85%\n",
      "Epoch 32/50, Train Loss: 0.0980, Val Loss: 0.9440, Val Accuracy: 78.29%\n",
      "Epoch 33/50, Train Loss: 0.0915, Val Loss: 1.0836, Val Accuracy: 75.98%\n",
      "Epoch 34/50, Train Loss: 0.0926, Val Loss: 1.0150, Val Accuracy: 77.32%\n",
      "Epoch 35/50, Train Loss: 0.0885, Val Loss: 1.0560, Val Accuracy: 76.74%\n",
      "Epoch 36/50, Train Loss: 0.0912, Val Loss: 1.0056, Val Accuracy: 76.51%\n",
      "Epoch 37/50, Train Loss: 0.0806, Val Loss: 1.0477, Val Accuracy: 77.04%\n",
      "Epoch 38/50, Train Loss: 0.0931, Val Loss: 0.9768, Val Accuracy: 77.67%\n",
      "Epoch 39/50, Train Loss: 0.0849, Val Loss: 1.0314, Val Accuracy: 77.07%\n",
      "Epoch 40/50, Train Loss: 0.0801, Val Loss: 1.0334, Val Accuracy: 76.93%\n",
      "Epoch 41/50, Train Loss: 0.0835, Val Loss: 0.9862, Val Accuracy: 77.25%\n",
      "Epoch 42/50, Train Loss: 0.0822, Val Loss: 0.9866, Val Accuracy: 77.90%\n",
      "Epoch 43/50, Train Loss: 0.0777, Val Loss: 0.9619, Val Accuracy: 78.29%\n",
      "Epoch 44/50, Train Loss: 0.0747, Val Loss: 0.9729, Val Accuracy: 77.70%\n",
      "Epoch 45/50, Train Loss: 0.0799, Val Loss: 1.0150, Val Accuracy: 77.98%\n",
      "Epoch 46/50, Train Loss: 0.0805, Val Loss: 0.9843, Val Accuracy: 77.51%\n",
      "Epoch 47/50, Train Loss: 0.0736, Val Loss: 0.9935, Val Accuracy: 78.28%\n",
      "Epoch 48/50, Train Loss: 0.0756, Val Loss: 0.9970, Val Accuracy: 77.94%\n",
      "Epoch 49/50, Train Loss: 0.0771, Val Loss: 1.0511, Val Accuracy: 77.09%\n",
      "Epoch 50/50, Train Loss: 0.0721, Val Loss: 1.0177, Val Accuracy: 77.79%\n"
     ]
    }
   ],
   "source": [
    "import torchvision, torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "\n",
    "# Transformations pour CIFAR-10\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Chargement des datasets\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='data/', train=True, transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='data/', train=False, transform=transform, download=True)\n",
    "\n",
    "# DataLoader\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4, pin_memory=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1000, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "# Définition du device\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# Classe Bottleneck\n",
    "class Bottleneck(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        mid_channels = out_channels // 4\n",
    "        \n",
    "        self.reduce = nn.Conv2d(in_channels, mid_channels, kernel_size=1, stride=stride, bias=False)\n",
    "        self.reduce_bn = nn.BatchNorm2d(mid_channels)\n",
    "        \n",
    "        self.maintain = nn.Conv2d(mid_channels, mid_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.maintain_bn = nn.BatchNorm2d(mid_channels)\n",
    "        \n",
    "        self.expand = nn.Conv2d(mid_channels, out_channels, kernel_size=1, stride=1, bias=False)\n",
    "        self.expand_bn = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.activation = nn.ReLU(inplace=True)\n",
    "        self.residual_connection = (in_channels == out_channels and stride == 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        \n",
    "        x = self.activation(self.reduce_bn(self.reduce(x)))\n",
    "        x = self.activation(self.maintain_bn(self.maintain(x)))\n",
    "        x = self.expand_bn(self.expand(x))\n",
    "        \n",
    "        if self.residual_connection:\n",
    "            x += identity\n",
    "        return self.activation(x)\n",
    "\n",
    "# Stacking de Bottlenecks\n",
    "class BottleneckStack(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, num_blocks, stride=1):\n",
    "        super(BottleneckStack, self).__init__()\n",
    "        layers = [Bottleneck(in_channels, out_channels, stride)]\n",
    "        layers += [Bottleneck(out_channels, out_channels, stride=1) for _ in range(num_blocks - 1)]\n",
    "        self.stack = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.stack(x)\n",
    "\n",
    "# Modèle principal\n",
    "class CIFAR10BottleneckNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CIFAR10BottleneckNet, self).__init__()\n",
    "        self.init_conv = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.init_bn = nn.BatchNorm2d(64)\n",
    "        self.init_relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.block1 = BottleneckStack(64, 128, num_blocks=3, stride=2)\n",
    "        self.block2 = BottleneckStack(128, 256, num_blocks=4, stride=2)\n",
    "        self.block3 = BottleneckStack(256, 512, num_blocks=6, stride=2)\n",
    "\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.init_relu(self.init_bn(self.init_conv(x)))\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.pool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Instanciation du modèle\n",
    "model = CIFAR10BottleneckNet().to(device)\n",
    "\n",
    "# Optimiseur et fonction de perte\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Boucle d'entraînement\n",
    "def train_one_epoch(model, train_loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "# Boucle de validation\n",
    "def validate(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "\n",
    "    accuracy = correct / len(test_loader.dataset)\n",
    "    return total_loss / len(test_loader), accuracy\n",
    "\n",
    "# Entraînement sur plusieurs époques\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
    "    val_loss, val_accuracy = validate(model, test_loader, criterion, device)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```text\n",
    "Inverted Bottleneck Block: Expands, maintains (via depthwise separable convolution), and reduces back.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch 1/50, Train Loss: 1.1711, Val Loss: 0.9166, Val Accuracy: 68.02%\n",
      "Epoch 2/50, Train Loss: 0.7127, Val Loss: 0.8171, Val Accuracy: 71.59%\n",
      "Epoch 3/50, Train Loss: 0.5478, Val Loss: 0.6463, Val Accuracy: 77.90%\n",
      "Epoch 4/50, Train Loss: 0.4394, Val Loss: 0.6813, Val Accuracy: 77.19%\n",
      "Epoch 5/50, Train Loss: 0.3701, Val Loss: 0.6597, Val Accuracy: 78.34%\n",
      "Epoch 6/50, Train Loss: 0.3142, Val Loss: 0.7045, Val Accuracy: 77.22%\n",
      "Epoch 7/50, Train Loss: 0.2647, Val Loss: 0.6637, Val Accuracy: 79.32%\n",
      "Epoch 8/50, Train Loss: 0.2328, Val Loss: 0.7332, Val Accuracy: 78.61%\n",
      "Epoch 9/50, Train Loss: 0.2096, Val Loss: 0.6884, Val Accuracy: 78.89%\n",
      "Epoch 10/50, Train Loss: 0.1826, Val Loss: 0.7953, Val Accuracy: 78.11%\n",
      "Epoch 11/50, Train Loss: 0.1622, Val Loss: 0.6809, Val Accuracy: 80.62%\n",
      "Epoch 12/50, Train Loss: 0.1626, Val Loss: 0.6646, Val Accuracy: 81.01%\n",
      "Epoch 13/50, Train Loss: 0.1401, Val Loss: 0.7223, Val Accuracy: 79.97%\n",
      "Epoch 14/50, Train Loss: 0.1333, Val Loss: 0.7286, Val Accuracy: 80.67%\n",
      "Epoch 15/50, Train Loss: 0.1305, Val Loss: 0.8145, Val Accuracy: 79.97%\n",
      "Epoch 16/50, Train Loss: 0.1190, Val Loss: 0.6985, Val Accuracy: 81.66%\n",
      "Epoch 17/50, Train Loss: 0.1242, Val Loss: 0.7427, Val Accuracy: 80.86%\n",
      "Epoch 18/50, Train Loss: 0.1131, Val Loss: 0.7669, Val Accuracy: 81.24%\n",
      "Epoch 19/50, Train Loss: 0.1086, Val Loss: 0.7225, Val Accuracy: 81.42%\n",
      "Epoch 20/50, Train Loss: 0.1101, Val Loss: 0.7222, Val Accuracy: 81.30%\n",
      "Epoch 21/50, Train Loss: 0.1053, Val Loss: 0.7536, Val Accuracy: 80.91%\n",
      "Epoch 22/50, Train Loss: 0.1030, Val Loss: 0.7768, Val Accuracy: 80.53%\n",
      "Epoch 23/50, Train Loss: 0.1021, Val Loss: 0.7197, Val Accuracy: 81.23%\n",
      "Epoch 24/50, Train Loss: 0.0932, Val Loss: 0.6987, Val Accuracy: 81.98%\n",
      "Epoch 25/50, Train Loss: 0.0933, Val Loss: 0.7431, Val Accuracy: 81.86%\n",
      "Epoch 26/50, Train Loss: 0.0945, Val Loss: 0.7130, Val Accuracy: 82.24%\n",
      "Epoch 27/50, Train Loss: 0.0902, Val Loss: 0.7584, Val Accuracy: 81.04%\n",
      "Epoch 28/50, Train Loss: 0.0917, Val Loss: 0.7907, Val Accuracy: 81.42%\n",
      "Epoch 29/50, Train Loss: 0.0862, Val Loss: 0.7087, Val Accuracy: 82.02%\n",
      "Epoch 30/50, Train Loss: 0.0875, Val Loss: 0.7571, Val Accuracy: 81.76%\n",
      "Epoch 31/50, Train Loss: 0.0834, Val Loss: 0.7292, Val Accuracy: 82.57%\n",
      "Epoch 32/50, Train Loss: 0.0859, Val Loss: 0.7603, Val Accuracy: 81.71%\n",
      "Epoch 33/50, Train Loss: 0.0856, Val Loss: 0.7796, Val Accuracy: 81.84%\n",
      "Epoch 34/50, Train Loss: 0.0857, Val Loss: 0.7292, Val Accuracy: 82.23%\n",
      "Epoch 35/50, Train Loss: 0.0747, Val Loss: 0.7154, Val Accuracy: 82.50%\n",
      "Epoch 36/50, Train Loss: 0.0826, Val Loss: 0.7816, Val Accuracy: 81.70%\n",
      "Epoch 37/50, Train Loss: 0.0785, Val Loss: 0.6924, Val Accuracy: 82.43%\n",
      "Epoch 38/50, Train Loss: 0.0736, Val Loss: 0.7456, Val Accuracy: 82.44%\n",
      "Epoch 39/50, Train Loss: 0.0764, Val Loss: 0.7186, Val Accuracy: 82.73%\n",
      "Epoch 40/50, Train Loss: 0.0807, Val Loss: 0.7398, Val Accuracy: 81.64%\n",
      "Epoch 41/50, Train Loss: 0.0723, Val Loss: 0.7831, Val Accuracy: 81.48%\n",
      "Epoch 42/50, Train Loss: 0.0780, Val Loss: 0.7384, Val Accuracy: 82.95%\n",
      "Epoch 43/50, Train Loss: 0.0759, Val Loss: 0.7129, Val Accuracy: 82.57%\n",
      "Epoch 44/50, Train Loss: 0.0663, Val Loss: 0.8134, Val Accuracy: 81.35%\n",
      "Epoch 45/50, Train Loss: 0.0718, Val Loss: 0.7521, Val Accuracy: 82.47%\n",
      "Epoch 46/50, Train Loss: 0.0781, Val Loss: 0.7010, Val Accuracy: 83.12%\n",
      "Epoch 47/50, Train Loss: 0.0630, Val Loss: 0.8958, Val Accuracy: 80.60%\n",
      "Epoch 48/50, Train Loss: 0.0683, Val Loss: 0.7297, Val Accuracy: 83.18%\n",
      "Epoch 49/50, Train Loss: 0.0691, Val Loss: 0.7403, Val Accuracy: 82.72%\n",
      "Epoch 50/50, Train Loss: 0.0676, Val Loss: 0.6889, Val Accuracy: 83.85%\n"
     ]
    }
   ],
   "source": [
    "import torchvision, torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "\n",
    "# Transformations pour CIFAR-10\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Chargement des datasets\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='data/', train=True, transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='data/', train=False, transform=transform, download=True)\n",
    "\n",
    "# DataLoader\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4, pin_memory=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1000, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "# Définition du device\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# Classe Inverted Bottleneck\n",
    "class InvertedBottleneck(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, expansion_factor, stride):\n",
    "        super(InvertedBottleneck, self).__init__()\n",
    "        mid_channels = in_channels * expansion_factor\n",
    "\n",
    "        self.use_residual = (in_channels == out_channels and stride == 1)\n",
    "\n",
    "        self.expand = nn.Conv2d(in_channels, mid_channels, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.expand_bn = nn.BatchNorm2d(mid_channels)\n",
    "\n",
    "        self.depthwise = nn.Conv2d(mid_channels, mid_channels, kernel_size=3, stride=stride, padding=1, groups=mid_channels, bias=False)\n",
    "        self.depthwise_bn = nn.BatchNorm2d(mid_channels)\n",
    "\n",
    "        self.project = nn.Conv2d(mid_channels, out_channels, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.project_bn = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.activation = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        x = self.activation(self.expand_bn(self.expand(x)))\n",
    "        x = self.activation(self.depthwise_bn(self.depthwise(x)))\n",
    "        x = self.project_bn(self.project(x))\n",
    "\n",
    "        if self.use_residual:\n",
    "            x += identity\n",
    "\n",
    "        return x\n",
    "\n",
    "# Stacking de Inverted Bottlenecks\n",
    "class InvertedBottleneckStack(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, num_blocks, expansion_factor, stride):\n",
    "        super(InvertedBottleneckStack, self).__init__()\n",
    "        layers = [InvertedBottleneck(in_channels, out_channels, expansion_factor, stride)]\n",
    "        layers += [InvertedBottleneck(out_channels, out_channels, expansion_factor, stride=1) for _ in range(num_blocks - 1)]\n",
    "        self.stack = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.stack(x)\n",
    "\n",
    "# Modèle principal avec Inverted Bottlenecks\n",
    "class CIFAR10InvertedBottleneckNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CIFAR10InvertedBottleneckNet, self).__init__()\n",
    "        self.init_conv = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.init_bn = nn.BatchNorm2d(32)\n",
    "        self.init_relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.block1 = InvertedBottleneckStack(32, 64, num_blocks=2, expansion_factor=6, stride=2)\n",
    "        self.block2 = InvertedBottleneckStack(64, 128, num_blocks=3, expansion_factor=6, stride=2)\n",
    "        self.block3 = InvertedBottleneckStack(128, 256, num_blocks=4, expansion_factor=6, stride=2)\n",
    "\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.init_relu(self.init_bn(self.init_conv(x)))\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.pool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Instanciation du modèle\n",
    "model = CIFAR10InvertedBottleneckNet().to(device)\n",
    "\n",
    "# Optimiseur et fonction de perte\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Boucle d'entraînement\n",
    "def train_one_epoch(model, train_loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "# Boucle de validation\n",
    "def validate(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "\n",
    "    accuracy = correct / len(test_loader.dataset)\n",
    "    return total_loss / len(test_loader), accuracy\n",
    "\n",
    "# Entraînement sur plusieurs époques\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
    "    val_loss, val_accuracy = validate(model, test_loader, criterion, device)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy * 100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
